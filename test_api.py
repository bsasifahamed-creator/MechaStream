#!/usr/bin/env python3
"""
Script simple para probar la API vLLM sin el modelo completo
"""

import requests
import json
import time
import sys

def test_health():
    """Probar endpoint de salud"""
    try:
        response = requests.get("http://localhost:8000/health", timeout=5)
        print(f"âœ… Health check: {response.status_code}")
        print(f"Response: {response.json()}")
        return True
    except requests.exceptions.RequestException as e:
        print(f"âŒ Health check failed: {e}")
        return False

def test_basic_info():
    """Probar endpoint bÃ¡sico"""
    try:
        response = requests.get("http://localhost:8000/", timeout=5)
        print(f"âœ… Basic info: {response.status_code}")
        print(f"Response: {response.json()}")
        return True
    except requests.exceptions.RequestException as e:
        print(f"âŒ Basic info failed: {e}")
        return False

def wait_for_server(max_attempts=30):
    """Esperar a que el servidor estÃ© listo"""
    print("ğŸ”„ Esperando a que el servidor vLLM estÃ© listo...")
    
    for attempt in range(max_attempts):
        try:
            response = requests.get("http://localhost:8000/health", timeout=2)
            if response.status_code == 200:
                data = response.json()
                if data.get("model_loaded", False):
                    print("âœ… Servidor listo y modelo cargado!")
                    return True
                else:
                    print(f"â³ Intento {attempt + 1}/{max_attempts}: Servidor activo, cargando modelo...")
            else:
                print(f"â³ Intento {attempt + 1}/{max_attempts}: Servidor iniciando...")
        except requests.exceptions.RequestException:
            print(f"â³ Intento {attempt + 1}/{max_attempts}: Esperando conexiÃ³n...")
        
        time.sleep(10)  # Esperar 10 segundos entre intentos
    
    print("âŒ Timeout esperando al servidor")
    return False

def test_generate():
    """Probar generaciÃ³n de texto"""
    try:
        payload = {
            "prompt": "Hola, Â¿cÃ³mo estÃ¡s?",
            "max_tokens": 50,
            "temperature": 0.7
        }
        
        response = requests.post(
            "http://localhost:8000/v1/generate", 
            json=payload, 
            timeout=30
        )
        
        print(f"âœ… Generate test: {response.status_code}")
        if response.status_code == 200:
            data = response.json()
            print(f"Generated text: {data.get('text', 'No text')}")
        else:
            print(f"Error response: {response.text}")
        return True
    except requests.exceptions.RequestException as e:
        print(f"âŒ Generate test failed: {e}")
        return False

def main():
    print("ğŸš€ Probando API vLLM...")
    print("=" * 50)
    
    # Probar conexiÃ³n bÃ¡sica primero
    if not test_basic_info():
        print("âŒ No se puede conectar al servidor. Â¿EstÃ¡ ejecutÃ¡ndose?")
        return
    
    # Esperar a que el modelo estÃ© cargado
    if not wait_for_server():
        print("âŒ El servidor no estÃ¡ listo despuÃ©s de esperar")
        print("ğŸ’¡ Esto puede ser normal si es la primera vez que ejecutas vLLM")
        print("ğŸ’¡ El modelo puede tardar 10-30 minutos en descargarse la primera vez")
        return
    
    # Probar generaciÃ³n
    print("\nğŸ§ª Probando generaciÃ³n de texto...")
    test_generate()
    
    print("\nâœ… Pruebas completadas!")
    print(f"ğŸŒ Tu aplicaciÃ³n Next.js: http://localhost:3001")
    print(f"ğŸ¤– API vLLM: http://localhost:8000")
    print(f"ğŸ“Š Health check: http://localhost:8000/health")

if __name__ == "__main__":
    main()