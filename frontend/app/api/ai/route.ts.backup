import { NextRequest, NextResponse } from 'next/server';
import { findMatchingTemplate } from '../../../lib/local-templates';

// API Keys with better validation
const GROQ_API_KEY = process.env.GROQ_API_KEY;
const OPENAI_API_KEY = process.env.OPENAI_API_KEY;
const OPENROUTER_API_KEY = process.env.OPENROUTER_API_KEY;
const GOOGLE_API_KEY = process.env.GOOGLE_API_KEY;

// Validate API keys
const hasValidGroq = GROQ_API_KEY && GROQ_API_KEY !== 'your_groq_api_key_here';
const hasValidOpenAI = OPENAI_API_KEY && OPENAI_API_KEY !== 'your_openai_api_key_here';
const hasValidOpenRouter = OPENROUTER_API_KEY && OPENROUTER_API_KEY !== 'your_openrouter_api_key_here';
const hasValidGoogle = GOOGLE_API_KEY && GOOGLE_API_KEY !== 'your_google_api_key_here';

interface LLMResponse {
  code?: string;
  explanation?: string;
  suggestions?: string[];
  error?: string;
  source?: string;
  model?: string;
}

function cleanCodeResponse(content: string): string {
  // Remove markdown code blocks and extract just the code
  const codeBlockRegex = /```(?:typescript|jsx|tsx|javascript|html|css)?\s*([\s\S]*?)```/g;
  const matches = content.match(codeBlockRegex);
  
  if (matches && matches.length > 0) {
    // If we have multiple code blocks, combine them
  if (matches.length > 1) {
      console.log('Found code blocks:', matches.length);
    let combinedCode = '';
    
      matches.forEach((match, index) => {
        const codeContent = match.replace(/```(?:typescript|jsx|tsx|javascript|html|css)?\s*/, '').replace(/```$/, '');
        console.log(`Processing code block: { fileName: 'unknown', codeLength: ${codeContent.length} }`);
        combinedCode += codeContent + '\n\n';
      });
    
    console.log('Combined code length:', combinedCode.length);
      return combinedCode.trim();
    } else {
      // Single code block
      const codeContent = matches[0].replace(/```(?:typescript|jsx|tsx|javascript|html|css)?\s*/, '').replace(/```$/, '');
      console.log('Single code block found, length:', codeContent.length);
      return codeContent.trim();
    }
  }
  
  // If no code blocks found, return the entire content
  return content.trim();
}

async function callOpenAI(prompt: string): Promise<LLMResponse> {
  try {
    const response = await fetch('https://api.openai.com/v1/chat/completions', {
      method: 'POST',
      headers: {
        'Authorization': `Bearer ${OPENAI_API_KEY}`,
        'Content-Type': 'application/json',
      },
      body: JSON.stringify({
        model: 'gpt-4',
        messages: [
          {
            role: 'system',
            content: 'You are an expert web developer. Generate complete, working code for the user\'s request. IMPORTANT: For Flask projects, separate your code into distinct code blocks: Use ```html for HTML content, Use ```css for CSS styles, Use ```javascript for JavaScript code. For React projects, provide complete React components. Always provide full HTML/CSS/JavaScript or React components that can run immediately.'
          },
          {
            role: 'user',
            content: prompt
          }
        ],
        max_tokens: 4000,
        temperature: 0.7,
      }),
    });

    if (!response.ok) {
      throw new Error(`OpenAI API error: ${response.status}`);
    }

    const data = await response.json();
    const content = data.choices[0]?.message?.content || '';
    const cleanedCode = cleanCodeResponse(content);
    
    return {
      code: cleanedCode,
      explanation: 'Generated using OpenAI GPT-4',
      source: 'openai',
      model: 'gpt-4'
    };
  } catch (error) {
    return { error: `OpenAI API error: ${error}` };
  }
}

async function callGroq(prompt: string): Promise<LLMResponse> {
  try {
    const response = await fetch('https://api.groq.com/openai/v1/chat/completions', {
      method: 'POST',
      headers: {
        'Authorization': `Bearer ${GROQ_API_KEY}`,
        'Content-Type': 'application/json',
      },
      body: JSON.stringify({
        model: 'mixtral-8x7b-32768',
        messages: [
          {
            role: 'system',
            content: 'You are an expert web developer. Generate complete, working code for the user\'s request. IMPORTANT: For Flask projects, separate your code into distinct code blocks: Use ```html for HTML content, Use ```css for CSS styles, Use ```javascript for JavaScript code. For React projects, provide complete React components. Always provide full HTML/CSS/JavaScript or React components that can run immediately.'
          },
          {
            role: 'user',
            content: prompt
          }
        ],
        max_tokens: 4000,
        temperature: 0.7,
      }),
    });

    if (!response.ok) {
      throw new Error(`Groq API error: ${response.status}`);
    }

    const data = await response.json();
    const content = data.choices[0]?.message?.content || '';
    const cleanedCode = cleanCodeResponse(content);
    
    return {
      code: cleanedCode,
      explanation: 'Generated using Groq Mixtral',
      source: 'groq',
      model: 'mixtral-8x7b-32768'
    };
  } catch (error) {
    return { error: `Groq API error: ${error}` };
  }
}

async function callOpenRouter(prompt: string): Promise<LLMResponse> {
  try {
    const response = await fetch('https://openrouter.ai/api/v1/chat/completions', {
      method: 'POST',
      headers: {
        'Authorization': `Bearer ${OPENROUTER_API_KEY}`,
        'Content-Type': 'application/json',
      },
      body: JSON.stringify({
        model: 'anthropic/claude-3.5-sonnet',
        messages: [
          {
            role: 'system',
            content: 'You are an expert web developer. Generate complete, working code for the user\'s request. IMPORTANT: For Flask projects, separate your code into distinct code blocks: Use ```html for HTML content, Use ```css for CSS styles, Use ```javascript for JavaScript code. For React projects, provide complete React components. Always provide full HTML/CSS/JavaScript or React components that can run immediately.'
          },
          {
            role: 'user',
            content: prompt
          }
        ],
        max_tokens: 4000,
        temperature: 0.7,
      }),
    });

    if (!response.ok) {
      throw new Error(`OpenRouter API error: ${response.status}`);
    }

    const data = await response.json();
    const content = data.choices[0]?.message?.content || '';
    const cleanedCode = cleanCodeResponse(content);
    
    return {
      code: cleanedCode,
      explanation: 'Generated using OpenRouter Claude',
      source: 'openrouter',
      model: 'claude-3.5-sonnet'
    };
  } catch (error) {
    return { error: `OpenRouter API error: ${error}` };
  }
}

async function callGoogle(prompt: string): Promise<LLMResponse> {
  try {
    const response = await fetch(`https://generativelanguage.googleapis.com/v1/models/gemini-1.5-flash:generateContent?key=${GOOGLE_API_KEY}`, {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
      },
      body: JSON.stringify({
        contents: [
          {
            parts: [
              {
                text: `You are an expert web developer. Generate complete, working code for the user's request. IMPORTANT: For Flask projects, separate your code into distinct code blocks: Use \`\`\`html for HTML content, Use \`\`\`css for CSS styles, Use \`\`\`javascript for JavaScript code. For React projects, provide complete React components. Always provide full HTML/CSS/JavaScript or React components that can run immediately.\n\nUser request: ${prompt}`
              }
            ]
          }
        ],
        generationConfig: {
          maxOutputTokens: 4000,
          temperature: 0.7,
        },
      }),
    });

    if (!response.ok) {
      throw new Error(`Google API error: ${response.status}`);
    }

    const data = await response.json();
    const content = data.candidates[0]?.content?.parts[0]?.text || '';
    const cleanedCode = cleanCodeResponse(content);
    
    return {
      code: cleanedCode,
      explanation: 'Generated using Google Gemini',
      source: 'google',
      model: 'gemini-pro'
    };
  } catch (error) {
    return { error: `Google API error: ${error}` };
  }
}

async function callOllama(prompt: string): Promise<LLMResponse> {
  try {
    console.log('ü¶ô Trying Ollama DeepSeek Coder (local)...');
    
    // First check if Ollama is running
    try {
      const controller = new AbortController();
      const timeoutId = setTimeout(() => controller.abort(), 5000);
      
      const statusResponse = await fetch('http://localhost:11434/api/tags', { 
        signal: controller.signal 
      });
      
      clearTimeout(timeoutId);
      
      if (!statusResponse.ok) {
        throw new Error('Ollama not running');
      }
    } catch (error) {
      return { error: 'Ollama not running locally. Please start Ollama first.' };
    }
    
    const response = await fetch('http://localhost:11434/api/generate', {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
      },
      body: JSON.stringify({
        model: 'deepseek-coder:6.7b',
          prompt: `You are an expert web developer. Generate complete, working code for the user's request. 

IMPORTANT: For Flask projects, separate your code into distinct code blocks:
- Use \`\`\`html for HTML content
- Use \`\`\`css for CSS styles  
- Use \`\`\`javascript for JavaScript code

For React projects, provide complete React components.

Always provide full HTML/CSS/JavaScript or React components that can run immediately.

User request: ${prompt}`,
          stream: false,
          options: {
            temperature: 0.7,
            num_predict: 4000,
          },
        }),
    });
    
    if (!response.ok) {
      const errorText = await response.text();
      console.log('Ollama API error response:', errorText);
      return { error: `Ollama API error: ${response.status} - ${errorText}` };
    }

    const data = await response.json();
    
    // Ollama returns the response directly in the 'response' field
    const content = data.response || '';
    
    if (!content) {
      return { error: 'Ollama returned empty response' };
    }
    
    const cleanedCode = cleanCodeResponse(content);
    
    return {
      code: cleanedCode,
      explanation: 'Generated using Ollama DeepSeek Coder',
      source: 'ollama',
      model: 'deepseek-coder:6.7b'
    };
  } catch (error) {
    return { error: `Ollama API error: ${error}` };
  }
}

function detectExecutionCommand(prompt: string): { isExecutionCommand: boolean; command: string; operation?: string; details?: any } {
  const lowerPrompt = prompt.toLowerCase();
  
  // File creation commands
  if (lowerPrompt.includes('create file') || lowerPrompt.includes('create a file') || lowerPrompt.includes('add file')) {
    return {
      isExecutionCommand: true,
      command: 'create',
      operation: 'create',
      details: { type: 'file' }
    };
  }
  
  // Component addition commands
  if (lowerPrompt.includes('add component') || lowerPrompt.includes('create component') || lowerPrompt.includes('add this component')) {
    return {
      isExecutionCommand: true,
      command: 'add-component',
      operation: 'add-component',
      details: { type: 'component' }
    };
  }
  
  // File modification commands
  if (lowerPrompt.includes('update') || lowerPrompt.includes('modify') || lowerPrompt.includes('change')) {
    return {
      isExecutionCommand: true,
      command: 'modify',
      operation: 'modify',
      details: { type: 'modification' }
    };
  }
  
  // File deletion commands
  if (lowerPrompt.includes('delete') || lowerPrompt.includes('remove') || lowerPrompt.includes('delete file')) {
    return {
      isExecutionCommand: true,
      command: 'delete',
      operation: 'delete',
      details: { type: 'deletion' }
    };
  }
  
  // Code update commands
  if (lowerPrompt.includes('update code') || lowerPrompt.includes('modify code') || lowerPrompt.includes('change code')) {
    return {
      isExecutionCommand: true,
      command: 'update',
      operation: 'update',
      details: { type: 'code-update' }
    };
  }
  
  return { isExecutionCommand: false, command: '' };
}

export async function POST(req: NextRequest) {
  try {
    const body = await req.json();
    const { prompt, provider = 'fallback', features = [], enableAgenticSearch = false, projectName } = body;
    
    if (!prompt) {
      return NextResponse.json({ error: 'Prompt is required' }, { status: 400 });
    }
    
    // Use original prompt without cache busting to avoid rate limits
    const cleanPrompt = prompt;
    
    console.log('AI API called with prompt:', cleanPrompt);
    console.log('Features:', features);
    console.log('Provider:', provider);
    console.log('Enable Agentic Search:', enableAgenticSearch);
    
    // Check if this is an execution command
    const executionCommand = detectExecutionCommand(prompt);
    if (executionCommand.isExecutionCommand && projectName) {
      console.log('Execution command detected:', executionCommand);
      
      // Handle execution command by calling the execute-command API
      try {
        const executeResponse = await fetch(`${process.env.NEXT_PUBLIC_BASE_URL || 'http://localhost:3001'}/api/execute-command`, {
          method: 'POST',
          headers: {
            'Content-Type': 'application/json',
          },
          body: JSON.stringify({
            command: prompt,
            projectName: projectName,
            operation: executionCommand.operation,
            details: executionCommand.details
          })
        });

        if (executeResponse.ok) {
          const executeResult = await executeResponse.json() as { message: string; files?: string[] };
          return NextResponse.json({
            code: `// ${executeResult.message}\n// Files updated: ${executeResult.files?.join(', ') || 'No files'}`,
            explanation: executeResult.message,
            suggestions: ['Continue with more commands', 'View the updated files', 'Run the project'],
            source: 'execution-command',
            model: 'file-operation',
            usage: { total_tokens: 0 },
            isExecutionCommand: true,
            executionResult: executeResult
          });
        } else {
          const errorData = await executeResponse.json() as { error: string };
          return NextResponse.json({
            code: `// Error: ${errorData.error}`,
            explanation: `Failed to execute command: ${errorData.error}`,
            suggestions: ['Check the project name', 'Verify file paths', 'Try a different command'],
            source: 'execution-command',
            model: 'file-operation',
            usage: { total_tokens: 0 },
            error: errorData.error
          });
        }
    } catch (error) {
        console.error('Execution command error:', error);
        return NextResponse.json({
          code: `// Error: ${error instanceof Error ? error.message : 'Failed to execute command'}`,
          explanation: 'Failed to execute the command. Please try again.',
          suggestions: ['Check your connection', 'Verify the project exists', 'Try a simpler command'],
          source: 'execution-command',
          model: 'file-operation',
          usage: { total_tokens: 0 },
          error: error instanceof Error ? error.message : 'Unknown error'
        });
      }
    }
    
    // Enhanced prompt based on features (with auto-detection from prompt text)
    let enhancedPrompt = cleanPrompt;

    const promptLower = cleanPrompt.toLowerCase();
    const ALWAYS_UI_UX = true; // force UI/UX emphasis
    const wantsUIDesign =
      ALWAYS_UI_UX ||
      features.includes('ui-ux-design') ||
      /ui\b|ux\b|design|beautiful|stunning|modern|visual|tailwind|responsive|animation|glassmorphism|neumorphism/.test(promptLower);

    if (features.includes('deep-research')) {
      enhancedPrompt = `${cleanPrompt}\n\nPlease provide comprehensive research with multiple sources, detailed analysis, and extended reasoning. Include relevant examples and practical applications.`;
    } else if (wantsUIDesign) {
      enhancedPrompt = `${cleanPrompt}\n\nDesign requirements: Use a modern, visually appealing UI with strong UX. Prefer responsive layouts, generous spacing, clear hierarchy, and accessible contrast. If generating Flask HTML, include <script src='https://cdn.tailwindcss.com'></script> in <head> and use Tailwind utility classes. For React, also use Tailwind classes. Add subtle transitions/hover states and ensure the layout looks polished on mobile and desktop.`;
    } else if (features.includes('code-optimization')) {
      enhancedPrompt = `${cleanPrompt}\n\nPlease provide optimized, efficient code with best practices, performance considerations, and clean architecture.`;
    } else if (features.includes('educational')) {
      enhancedPrompt = `${cleanPrompt}\n\nPlease provide educational explanations with examples, best practices, and learning resources.`;
    }
    
    // Get available APIs with proper validation
    const availableApis: string[] = [];
    
    // Check each API with proper validation
    if (hasValidGroq) availableApis.push('groq');
    if (hasValidOpenAI) availableApis.push('openai');
    if (hasValidOpenRouter) availableApis.push('openrouter');
    if (hasValidGoogle) availableApis.push('google');
    
    // Always add Ollama as local fallback
    availableApis.push('ollama');
    
    // Prioritize based on observed reliability (google often succeeds here)
    const apiPriority = ['google', 'groq', 'openrouter', 'ollama', 'openai'];
    const prioritizedApis = apiPriority.filter(api => availableApis.includes(api));
    
    console.log('Available APIs:', availableApis);
    console.log('Prioritized APIs:', prioritizedApis);
    console.log('API Status:', {
      groq: hasValidGroq ? '‚úÖ Available' : '‚ùå Not configured',
      openai: hasValidOpenAI ? '‚úÖ Available' : '‚ùå Not configured', 
      openrouter: hasValidOpenRouter ? '‚úÖ Available' : '‚ùå Not configured',
      google: hasValidGoogle ? '‚úÖ Available' : '‚ùå Not configured',
      ollama: '‚úÖ Always available (local)'
    });
    
    let response: LLMResponse;
    
    // Try APIs in order with better error handling and timeout
    for (const apiName of prioritizedApis) {
      console.log('Trying', apiName, 'API...');
      
      try {
        // Add timeout to prevent hanging - shorter timeout for faster fallback
        const timeoutPromise = new Promise((_, reject) => 
          setTimeout(() => reject(new Error('API timeout')), 10000) // 10 second timeout for faster fallback
        );
        
        const apiCallPromise = (async () => {
          switch (apiName) {
            case 'openai':
              return await callOpenAI(enhancedPrompt);
            case 'groq':
              return await callGroq(enhancedPrompt);
            case 'openrouter':
              return await callOpenRouter(enhancedPrompt);
            case 'google':
            
              // Try Google API twice with a short delay
              let googleResponse = await callGoogle(enhancedPrompt);
              const is503 = Boolean(googleResponse && (googleResponse as any).error && typeof (googleResponse as any).error === 'string' && (googleResponse as any).error.includes('503'));
              if (is503) {
                console.log('Google API returned 503, retrying once...');
                await new Promise(resolve => setTimeout(resolve, 2000));
                googleResponse = await callGoogle(enhancedPrompt);
              }
              return googleResponse;
            case 'ollama':
              return await callOllama(enhancedPrompt);
            default:
              return { error: 'Unknown API' };
          }
        })();
        
        response = await Promise.race([apiCallPromise, timeoutPromise]) as LLMResponse;
        
        // If we got a successful response, break out of the loop
        if (response.code && !response.error) {
          console.log(`‚úÖ ${apiName} API call successful with code length:`, response.code.length);
          console.log(`üéØ Using ${apiName} for this request`);
          return NextResponse.json({
            code: response.code,
            explanation: response.explanation || '',
            suggestions: response.suggestions || [],
            source: response.source || 'LLM',
            model: response.model || apiName,
            usage: { total_tokens: 0 }
          });
        }
        
        // Log what we got for debugging
        console.log(`${apiName} API response:`, {
          hasCode: !!response.code,
          codeLength: response.code?.length || 0,
          hasError: !!response.error,
          error: response.error
        });
        
        // If we got an error, log it and continue to next API
        if (response.error) {
          console.log(`${apiName} API error:`, response.error);
          
          // Special handling for rate limits - wait a bit before trying next API
          if (response.error.includes('Too Many Requests') || response.error.includes('rate limit')) {
            console.log(`‚è≥ Rate limit hit for ${apiName}, waiting 3 seconds...`);
            await new Promise(resolve => setTimeout(resolve, 3000));
          } else if (response.error.includes('Payment Required')) {
            console.log(`üí≥ Payment required for ${apiName}, skipping...`);
          } else if (response.error.includes('Not Found')) {
            console.log(`üîç API endpoint not found for ${apiName}, skipping...`);
          }
          
          continue;
        }
        
      } catch (error) {
        console.log(`${apiName} API failed:`, error);
        continue;
      }
    }
    
    // If all APIs fail, return error - no fallbacks
    console.log('‚ùå All APIs failed - returning error');
    return NextResponse.json({
      error: 'All AI services are currently unavailable. Please try again in a few moments.',
      suggestions: [
        'Wait 30 seconds and try again', 
        'Check your internet connection', 
        'Try a simpler prompt',
        'Make sure Ollama is running locally',
        'Check your API keys in .env.local',
        'Try restarting the development server'
      ],
      source: 'api-failure',
      model: 'none'
    }, { status: 503 });
    
  } catch (error) {
    console.error('API error:', error);
    return NextResponse.json(
      { error: 'Internal server error' },
      { status: 500 }
    );
  }
}